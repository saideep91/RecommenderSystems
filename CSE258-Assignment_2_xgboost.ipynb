{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import linear_model\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score ,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"short_description\": \"She left her husband. He killed their children. Just another day in America.\", \"headline\": \"There Were 2 Mass Shootings In Texas Last Week, But Only 1 On TV\", \"date\": \"2018-05-26\", \"link\": \"https://www.huffingtonpost.com/entry/texas-amanda-painter-mass-shooting_us_5b081ab4e4b0802d69caad89\", \"authors\": \"Melissa Jeltsen\", \"category\": \"CRIME\"}\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for l in open('News_Category_Dataset.json'):\n",
    "    print (l)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readjson(f):\n",
    "  for l in open(f):\n",
    "    yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([u'all', u'just', u\"don't\", u'being', u'over', u'both', u'through', u'yourselves', u'its', u'before', u'o', u'don', u'hadn', u'herself', u'll', u'had', u'should', u'to', u'only', u'won', u'under', u'ours', u'has', u\"should've\", u\"haven't\", u'do', u'them', u'his', u'very', u\"you've\", u'they', u'not', u'during', u'now', u'him', u'nor', u\"wasn't\", u'd', u'did', u'didn', u'this', u'she', u'each', u'further', u\"won't\", u'where', u\"mustn't\", u\"isn't\", u'few', u'because', u\"you'd\", u'doing', u'some', u'hasn', u\"hasn't\", u'are', u'our', u'ourselves', u'out', u'what', u'for', u\"needn't\", u'below', u're', u'does', u\"shouldn't\", u'above', u'between', u'mustn', u't', u'be', u'we', u'who', u\"mightn't\", u\"doesn't\", u'were', u'here', u'shouldn', u'hers', u\"aren't\", u'by', u'on', u'about', u'couldn', u'of', u\"wouldn't\", u'against', u's', u'isn', u'or', u'own', u'into', u'yourself', u'down', u\"hadn't\", u'mightn', u\"couldn't\", u'wasn', u'your', u\"you're\", u'from', u'her', u'their', u'aren', u\"it's\", u'there', u'been', u'whom', u'too', u'wouldn', u'themselves', u'weren', u'was', u'until', u'more', u'himself', u'that', u\"didn't\", u'but', u\"that'll\", u'with', u'than', u'those', u'he', u'me', u'myself', u'ma', u\"weren't\", u'these', u'up', u'will', u'while', u'ain', u'can', u'theirs', u'my', u'and', u've', u'then', u'is', u'am', u'it', u'doesn', u'an', u'as', u'itself', u'at', u'have', u'in', u'any', u'if', u'again', u'no', u'when', u'same', u'how', u'other', u'which', u'you', u\"shan't\", u'shan', u'needn', u'haven', u'after', u'most', u'such', u'why', u'a', u'off', u'i', u'm', u'yours', u\"you'll\", u'so', u'y', u\"she's\", u'the', u'having', u'once'])\n"
     ]
    }
   ],
   "source": [
    "data=readjson('News_Category_Dataset.json')\n",
    "data=list(data)\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "sw = set(stopwords.words('english'))\n",
    "print (sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = [d['short_description']+\" \"+d['headline']+\" \"+d['authors'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf=TfidfVectorizer(analyzer = \"word\", max_features=5000, stop_words=sw)\n",
    "X = tfidf.fit_transform(w).toarray()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [d['category'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5000 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.39\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model = LinearSVC()\n",
    "model.fit(X_train,y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test,y_predict)*100\n",
    "print(format(accuracy, '.2f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3000 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylabel_id = dict(zip(list(set(y)), range(31)) )\n",
    "dtrain=[ int(ylabel_id[d])  for d in y ]\n",
    "X=numpy.array(X)\n",
    "y=numpy.array(dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_train = xgb.DMatrix(X_train, label=y_train)\n",
    "xg_test = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 6\n",
    "param['silent'] = 1\n",
    "param['nthread'] = 4\n",
    "param['num_class'] = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.490164\ttest-merror:0.499200\n",
      "[1]\ttrain-merror:0.448880\ttest-merror:0.460437\n",
      "[2]\ttrain-merror:0.434859\ttest-merror:0.447676\n",
      "[3]\ttrain-merror:0.431749\ttest-merror:0.447876\n",
      "[4]\ttrain-merror:0.428269\ttest-merror:0.442275\n",
      "[5]\ttrain-merror:0.426148\ttest-merror:0.440715\n",
      "[6]\ttrain-merror:0.423458\ttest-merror:0.438235\n",
      "[7]\ttrain-merror:0.420848\ttest-merror:0.437515\n",
      "[8]\ttrain-merror:0.417898\ttest-merror:0.435115\n",
      "[9]\ttrain-merror:0.415177\ttest-merror:0.434435\n",
      "[10]\ttrain-merror:0.413327\ttest-merror:0.433115\n",
      "[11]\ttrain-merror:0.411367\ttest-merror:0.431675\n",
      "[12]\ttrain-merror:0.408567\ttest-merror:0.429474\n",
      "[13]\ttrain-merror:0.407257\ttest-merror:0.428354\n",
      "[14]\ttrain-merror:0.406037\ttest-merror:0.428514\n",
      "[15]\ttrain-merror:0.403026\ttest-merror:0.426074\n",
      "[16]\ttrain-merror:0.401076\ttest-merror:0.425234\n",
      "[17]\ttrain-merror:0.398366\ttest-merror:0.423114\n",
      "[18]\ttrain-merror:0.396206\ttest-merror:0.420674\n",
      "[19]\ttrain-merror:0.392565\ttest-merror:0.418714\n",
      "[20]\ttrain-merror:0.391175\ttest-merror:0.418313\n",
      "[21]\ttrain-merror:0.389115\ttest-merror:0.417433\n",
      "[22]\ttrain-merror:0.387175\ttest-merror:0.417033\n",
      "[23]\ttrain-merror:0.385105\ttest-merror:0.415833\n",
      "[24]\ttrain-merror:0.383935\ttest-merror:0.414593\n",
      "[25]\ttrain-merror:0.382254\ttest-merror:0.413553\n",
      "[26]\ttrain-merror:0.381164\ttest-merror:0.413753\n",
      "[27]\ttrain-merror:0.379584\ttest-merror:0.411953\n",
      "[28]\ttrain-merror:0.377864\ttest-merror:0.410993\n",
      "[29]\ttrain-merror:0.376724\ttest-merror:0.410513\n",
      "[30]\ttrain-merror:0.374524\ttest-merror:0.408313\n",
      "[31]\ttrain-merror:0.372994\ttest-merror:0.407113\n",
      "[32]\ttrain-merror:0.371413\ttest-merror:0.405632\n",
      "[33]\ttrain-merror:0.370183\ttest-merror:0.404952\n",
      "[34]\ttrain-merror:0.368423\ttest-merror:0.403032\n",
      "[35]\ttrain-merror:0.366933\ttest-merror:0.402432\n",
      "[36]\ttrain-merror:0.365583\ttest-merror:0.401192\n",
      "[37]\ttrain-merror:0.364183\ttest-merror:0.400072\n",
      "[38]\ttrain-merror:0.362553\ttest-merror:0.399632\n",
      "[39]\ttrain-merror:0.360722\ttest-merror:0.397992\n",
      "[40]\ttrain-merror:0.359882\ttest-merror:0.397752\n",
      "[41]\ttrain-merror:0.358612\ttest-merror:0.397432\n",
      "[42]\ttrain-merror:0.356992\ttest-merror:0.396672\n",
      "[43]\ttrain-merror:0.355832\ttest-merror:0.395352\n",
      "[44]\ttrain-merror:0.353872\ttest-merror:0.393872\n",
      "[45]\ttrain-merror:0.352572\ttest-merror:0.393311\n",
      "[46]\ttrain-merror:0.351272\ttest-merror:0.392831\n",
      "[47]\ttrain-merror:0.350242\ttest-merror:0.391831\n",
      "[48]\ttrain-merror:0.348781\ttest-merror:0.391511\n",
      "[49]\ttrain-merror:0.347221\ttest-merror:0.391031\n",
      "[50]\ttrain-merror:0.345671\ttest-merror:0.390631\n",
      "[51]\ttrain-merror:0.344471\ttest-merror:0.389591\n",
      "[52]\ttrain-merror:0.343371\ttest-merror:0.388671\n",
      "[53]\ttrain-merror:0.342131\ttest-merror:0.387951\n",
      "[54]\ttrain-merror:0.340591\ttest-merror:0.387831\n",
      "[55]\ttrain-merror:0.339281\ttest-merror:0.386871\n",
      "[56]\ttrain-merror:0.338190\ttest-merror:0.385911\n",
      "[57]\ttrain-merror:0.336980\ttest-merror:0.385391\n",
      "[58]\ttrain-merror:0.335550\ttest-merror:0.384671\n",
      "[59]\ttrain-merror:0.334640\ttest-merror:0.384111\n",
      "[60]\ttrain-merror:0.333020\ttest-merror:0.383431\n",
      "[61]\ttrain-merror:0.331870\ttest-merror:0.382471\n",
      "[62]\ttrain-merror:0.330700\ttest-merror:0.381671\n",
      "[63]\ttrain-merror:0.329180\ttest-merror:0.380550\n",
      "[64]\ttrain-merror:0.328180\ttest-merror:0.379630\n",
      "[65]\ttrain-merror:0.326909\ttest-merror:0.378990\n",
      "[66]\ttrain-merror:0.326039\ttest-merror:0.378310\n",
      "[67]\ttrain-merror:0.324869\ttest-merror:0.378390\n",
      "[68]\ttrain-merror:0.323689\ttest-merror:0.377790\n",
      "[69]\ttrain-merror:0.322579\ttest-merror:0.377150\n",
      "[70]\ttrain-merror:0.320969\ttest-merror:0.376390\n",
      "[71]\ttrain-merror:0.320189\ttest-merror:0.376190\n",
      "[72]\ttrain-merror:0.318859\ttest-merror:0.375350\n",
      "[73]\ttrain-merror:0.317949\ttest-merror:0.374710\n",
      "[74]\ttrain-merror:0.316698\ttest-merror:0.373750\n",
      "[75]\ttrain-merror:0.315638\ttest-merror:0.373270\n",
      "[76]\ttrain-merror:0.314558\ttest-merror:0.372670\n",
      "[77]\ttrain-merror:0.313708\ttest-merror:0.372390\n",
      "[78]\ttrain-merror:0.312488\ttest-merror:0.371150\n",
      "[79]\ttrain-merror:0.311708\ttest-merror:0.371070\n",
      "[80]\ttrain-merror:0.310878\ttest-merror:0.370550\n",
      "[81]\ttrain-merror:0.309698\ttest-merror:0.370310\n",
      "[82]\ttrain-merror:0.308638\ttest-merror:0.368910\n",
      "[83]\ttrain-merror:0.307838\ttest-merror:0.368309\n",
      "[84]\ttrain-merror:0.306628\ttest-merror:0.367509\n",
      "[85]\ttrain-merror:0.305878\ttest-merror:0.367109\n",
      "[86]\ttrain-merror:0.304477\ttest-merror:0.366509\n",
      "[87]\ttrain-merror:0.303577\ttest-merror:0.365589\n",
      "[88]\ttrain-merror:0.302677\ttest-merror:0.364989\n",
      "[89]\ttrain-merror:0.301907\ttest-merror:0.364709\n",
      "[90]\ttrain-merror:0.300907\ttest-merror:0.364229\n",
      "[91]\ttrain-merror:0.300107\ttest-merror:0.363669\n",
      "[92]\ttrain-merror:0.299037\ttest-merror:0.362989\n",
      "[93]\ttrain-merror:0.298007\ttest-merror:0.362509\n",
      "[94]\ttrain-merror:0.297477\ttest-merror:0.361829\n",
      "[95]\ttrain-merror:0.296627\ttest-merror:0.361629\n",
      "[96]\ttrain-merror:0.295927\ttest-merror:0.361789\n",
      "[97]\ttrain-merror:0.295197\ttest-merror:0.360869\n",
      "[98]\ttrain-merror:0.294527\ttest-merror:0.360069\n",
      "[99]\ttrain-merror:0.293626\ttest-merror:0.359589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error using softmax = 0.359588767101\n"
     ]
    }
   ],
   "source": [
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 100\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# get prediction\n",
    "pred = bst.predict(xg_test)\n",
    "error_rate = numpy.sum(pred != y_test) / (y_test.shape[0]+0.0)\n",
    "print('Test error using softmax = {}'.format(error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
